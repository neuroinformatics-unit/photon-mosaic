configfile: "workflow/config.yaml"

from pathlib import Path
from photon_mosaic.dataset_discovery import discover_datasets
from photon_mosaic.rules.preprocessing import get_input_files

raw_data_base = Path(config["raw_data_base"])
processed_data_base = Path(config["processed_data_base"])
slurm_config = config.get("slurm", {})

# Discover datasets
datasets_old_names = discover_datasets(
    str(raw_data_base),
    pattern=config["dataset_discovery"]["pattern"],
    exclude_patterns=config["dataset_discovery"].get("exclude_patterns"),
)
datasets_new_names = discover_datasets(
    str(raw_data_base),
    pattern=config["dataset_discovery"]["pattern"],
    exclude_patterns=config["dataset_discovery"].get("exclude_patterns"),
    substitutions=config["dataset_discovery"].get("substitutions"),
)

# Mapping old_name -> new_name
dataset_pairs = list(zip(datasets_old_names, datasets_new_names))
output_patterns = config["preprocessing"]["output_patterns"]


# Suite2p outputs
suite2p_outputs = [
    processed_data_base / f"sub-{i}_{new}" / f"ses-{j}" / "funcimg" / "suite2p" / "plane0" / fname
    for i, (_, new) in enumerate(dataset_pairs)
    for j in range(len(output_patterns))
    for fname in ["F.npy", "data.bin"]
]

# Build a list of all sample identifiers as tuples (sub_idx, ses_idx)
SAMPLE_PAIRS = [
    (f"{i}", f"{j}")
    for i in range(len(datasets_new_names))
    for j in range(len(output_patterns))
]

include: "preprocessing.smk"
include: "suite2p.smk"

preproc_targets = [
    f"{processed_data_base}/sub-{i}_{datasets_new_names[i]}/ses-{j}/funcimg/{output_patterns[j]}"
    for i in range(len(datasets_new_names))
    for j in range(len(output_patterns))
]

suite2p_targets = [
    f"{processed_data_base}/sub-{i}_{datasets_new_names[i]}/ses-{j}/funcimg/suite2p/plane0/{fname}"
    for i in range(len(datasets_new_names))
    for j in range(len(output_patterns))
    for fname in ["F.npy", "data.bin"]
]

rule all:
    input:
        preproc_targets + suite2p_targets
