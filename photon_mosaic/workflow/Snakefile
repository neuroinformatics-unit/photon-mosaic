"""
Photon Mosaic Main Workflow

This is the main Snakefile that orchestrates the entire photon mosaic processing pipeline.
It handles dataset discovery, target generation, and coordinates the preprocessing,
suite2p analysis, and dF/F calculation workflows.

The workflow:
1. Discovers datasets and their TIFF files from the raw data directory
2. Generates preprocessing targets for each dataset/session combination
3. Generates suite2p analysis targets for processed data
4. Generates dff calculation targets for processed data
5. Includes preprocessing.smk, suite2p.smk, dff.smk modules to execute the actual processing
"""

from pathlib import Path
from photon_mosaic.dataset_discovery import DatasetDiscoverer
import logging
from photon_mosaic.logging_config import (
    setup_logging,
    log_section_header,
    log_subsection,
    log_list_summary,
)

# Configure logging with centralized setup from photon_mosaic.logging_config
log_level_str = (
    "DEBUG" if config.get("logging", {}).get("snakemake_verbose", False) else "INFO"
)

setup_logging(log_level=log_level_str, use_colors=False)
logger = logging.getLogger("snakemake.workflow")


raw_data_base = Path(config["raw_data_base"]).resolve()
processed_data_base = Path(config["processed_data_base"]).resolve()
slurm_config = config.get("slurm", {})
output_pattern = config["preprocessing"]["output_pattern"]

log_section_header(logger, "Configuration")
logger.info(f"Raw data base: {raw_data_base}")
logger.info(f"Processed data base: {processed_data_base}")

# Log SLURM configuration
use_slurm = config.get("use_slurm", False)
if use_slurm:
    log_section_header(logger, "SLURM Configuration")
    logger.info("SLURM execution: ENABLED")
    logger.info(f"Configuration: {slurm_config}")
else:
    log_section_header(logger, "Execution Mode")
    logger.info("SLURM execution: DISABLED (running locally)")

# Discover datasets and their TIFF files using the new class-based approach
log_section_header(logger, "Dataset Discovery")
discoverer = DatasetDiscoverer(
    base_path=raw_data_base,
    pattern=config["dataset_discovery"].get("pattern", ".*"),
    exclude_datasets=config["dataset_discovery"].get("exclude_datasets"),
    exclude_sessions=config["dataset_discovery"].get("exclude_sessions"),
    tiff_patterns=config["dataset_discovery"].get("tiff_patterns"),
    neuroblueprint_format=config["dataset_discovery"].get(
        "neuroblueprint_format", False
    ),
)

discoverer.discover()

logger.info(
    f"Discovered {len(discoverer.transformed_datasets)} dataset(s): {discoverer.transformed_datasets}"
)
total_tiffs = sum(len(sessions) for sessions in discoverer.tiff_files.values())
logger.info(f"Found {total_tiffs} session(s) with TIFF files")

log_section_header(logger, "Generating Targets")

preproc_targets = [
    str(
        Path(processed_data_base)
        / dataset_name
        / discoverer.get_session_name(i, session_idx)
        / "funcimg"
        / f"{output_pattern}{Path(tiff_name).name}"
    )
    for i, dataset_name in enumerate(discoverer.transformed_datasets)
    for session_idx, tiff_list in discoverer.tiff_files[
        discoverer.original_datasets[i]
    ].items()
    for tiff_name in tiff_list
]

log_list_summary(logger, preproc_targets, "Preprocessing targets", preview_count=5)

suite2p_targets = [
    str(
        Path(processed_data_base)
        / dataset_name
        / discoverer.get_session_name(i, session_idx)
        / "funcimg"
        / "suite2p"
        / "plane0"
        / fname
    )
    for i, dataset_name in enumerate(discoverer.transformed_datasets)
    for session_idx, tiff_list in discoverer.tiff_files[
        discoverer.original_datasets[i]
    ].items()
    for fname in ["F.npy", "data.bin"]
    if tiff_list  # Only create targets for sessions that have files
]

log_list_summary(logger, suite2p_targets, "Suite2p targets", preview_count=3)

dff_targets = [
    str(
        Path(processed_data_base)
        / dataset_name
        / discoverer.get_session_name(i, session_idx)
        / "funcimg"
        / "dff"
        / "plane0"
        / fname
    )
    for i, dataset_name in enumerate(discoverer.transformed_datasets)
    for session_idx, tiff_list in discoverer.tiff_files[
        discoverer.original_datasets[i]
    ].items()
    for fname in ["dFF.npy"]
    if tiff_list  # Only create targets for sessions that have files
]

logger.info(f"dFF calculation targets: {dff_targets}")


include: "preprocessing.smk"
include: "suite2p.smk"
include: "dff.smk"


rule all:
    input:
        preproc_targets,
        suite2p_targets,
        dff_targets,
